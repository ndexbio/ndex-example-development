{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDF and OBO to NDEx and Back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses pronto for parsing and generating OBO and RDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Uncomment the next line if you need to install the pronto module\n",
    "#!pip install pronto\n",
    "import ndex2\n",
    "import pronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_username = 'drh'\n",
    "my_password = 'drh'\n",
    "my_ndex_server = 'public.ndexbio.org'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Protein Modification Ontology from an OBO file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING PSI-MOD...\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "print(\"LOADING PSI-MOD...\")\n",
    "ontology = pronto.Ontology(\"../resources/PSI-MOD.obo\")\n",
    "#ontology = pronto.Ontology(\"http://purl.obolibrary.org/obo/go/go-basic.obo\")\n",
    "#clear_output()\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_term_map(annotation_file_path):\n",
    "    header = [\"id_type\",\n",
    "              \"id\",\n",
    "              \"gene_symbol\",\n",
    "              \"x\",\n",
    "              \"go_id\",\n",
    "              \"reference_id\",\n",
    "              \"evidence_type\"]\n",
    "\n",
    "    term_map = {}\n",
    "\n",
    "    # Each row in the gene annotation file maps a gene to a GO term\n",
    "    # plus data about the gene and the source of the annotation\n",
    "\n",
    "    # We therefore first populate an inverse map: for each GO term id, a set of gene symbols\n",
    "    # (this could be more sophisticated in the future, but first we will do the minimum work)\n",
    "\n",
    "    gene_symbol_set = set()\n",
    "\n",
    "    with open(annotation_file_path, 'rU') as tsvfile:\n",
    "        reader = csv.DictReader(filter(lambda row: row[0] != '#', tsvfile), dialect='excel-tab', fieldnames=header)\n",
    "        for row in reader:\n",
    "            gene_symbol = row.get(\"gene_symbol\")\n",
    "            term_id = row.get(\"go_id\")\n",
    "           # print str(gene_symbol) + str(term_id)\n",
    "            if gene_symbol and term_id:\n",
    "                term_attributes = term_map.get(term_id)\n",
    "\n",
    "                if not term_attributes:\n",
    "                    term_attributes = {\"my_genes\": [], \"term_ids\": [term_id]}\n",
    "                    term_map[term_id] = term_attributes\n",
    "\n",
    "                my_genes = term_attributes[\"my_genes\"]\n",
    "                my_genes.append(gene_symbol)\n",
    "\n",
    "\n",
    "    # remove duplicates\n",
    "    for term_id in term_map:\n",
    "        attributes = term_map[term_id]\n",
    "        attributes[\"my_genes\"] = list(set(attributes[\"my_genes\"]))\n",
    "\n",
    "\n",
    "    # for each term-genes annotation, we add that annotation to the\n",
    "    # corresponding term in the ontology.\n",
    "\n",
    "    # Note that in the case that the annotations\n",
    "    # may only cover a subset of the ontology.\n",
    "\n",
    "    # for term_id, genes in term_id_to_genes_map:\n",
    "    #     term = ontology.get(term_id)\n",
    "    #     if not term:\n",
    "    #         print \"term id not found in ontology: \" + str(term_id)\n",
    "    #     else:\n",
    "    #         term[\"genes\"] = genes\n",
    "\n",
    "    print(str(len(term_map))) + \" terms annotated in term_map\"\n",
    "    return term_map\n",
    "\n",
    "def ontology2NiceCX(ontology, term_map, root_term_id):\n",
    "\n",
    "    root = ontology[root_term_id]\n",
    "    if not root:\n",
    "        raise \"cannot find root term by id \" + str(root_term_id)\n",
    "\n",
    "    term_id_to_node_id_map = {}\n",
    "    G = NiceCXNetwork()\n",
    "\n",
    "    print(\"adding nodes\")\n",
    "    # create all the nodes under root in ontology and add attributes, if any\n",
    "    add_nodes(root, G, term_map, term_id_to_node_id_map)\n",
    "\n",
    "    print(\"added \" + str(len(term_id_to_node_id_map)) + \" nodes\")\n",
    "    print(\"network now has  \" + str(len(G.nodes())) + \" nodes\")\n",
    "\n",
    "    print(\"adding edges\")\n",
    "    add_edges(root, G, term_id_to_node_id_map)\n",
    "    print(\"network now has  \" + str(len(G.edges())) + \" edges\")\n",
    "    return G\n",
    "\n",
    "def add_new_node(network, node_id, att_dict):\n",
    "    node = network_get_node_by_name(network, node_name)\n",
    "    if not node:\n",
    "        node = network_add_node(name)\n",
    "    \n",
    "def add_nodes(parent_term, network, term_map, term_id_to_node_id_map):\n",
    "\n",
    "    # check to see if this term has already been added to the id->node_id map\n",
    "    if parent_term.id in term_id_to_node_id_map:\n",
    "        return\n",
    "\n",
    "    # only traverse nodes in the term_map\n",
    "    if parent_term.id not in term_map:\n",
    "        return\n",
    "\n",
    "    attributes = term_map[parent_term.id]\n",
    "\n",
    "    # dont include this term if it has no propagated or directly annotated genes\n",
    "    if \"genes\" not in attributes or len(attributes[\"genes\"]) is 0:\n",
    "        return\n",
    "\n",
    "    att_dict = {}\n",
    "    att_dict[\"represents\"] = parent_term.id\n",
    "    # prune empty lists from attributes\n",
    "    for att in attributes:\n",
    "        val = attributes[att]\n",
    "        if not (type(val) is list and len(val) is 0):\n",
    "            att_dict[att] = val\n",
    "    node = network.add_node(parent_term.name, att_dict)\n",
    "    term_id_to_node_id_map[parent_term.id] = node.get_id()\n",
    "\n",
    "    for child_term in parent_term.children:\n",
    "        add_nodes(child_term, network, term_map, term_id_to_node_id_map)\n",
    "\n",
    "def add_edges(parent_term, network, term_id_to_node_id_map):\n",
    "    edge_id_counter = 1\n",
    "    if parent_term.id in term_id_to_node_id_map:\n",
    "        parent_node_id = term_id_to_node_id_map.get(parent_term.id)\n",
    "        for child_term in parent_term.children:\n",
    "            if child_term.id in term_id_to_node_id_map:\n",
    "                child_node_id = term_id_to_node_id_map.get(child_term.id)\n",
    "                if child_node_id == parent_node_id:\n",
    "                    print(\"self loop : \" + parent_term.name)\n",
    "                else:\n",
    "                    edge_count = network.number_of_edges(child_node_id, parent_node_id)\n",
    "                    if edge_count is 0:\n",
    "                        network.create_edge(id=edge_id_counter, edge_source=child_node_id, edge_target=parent_node_id, edge_interaction=\"hasParent\")\n",
    "                        #network.add_edge_between(child_node_id, parent_node_id, \"hasParent\")\n",
    "                        # print child_term.name + \" -> \" + parent_term.name\n",
    "                    add_edges(child_term, network, term_id_to_node_id_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
